{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "from collections import deque\n",
    "from time import sleep\n",
    "#import pickle \n",
    "#file_pi = open('DQN_Memory.obj', 'wb') \n",
    "\n",
    "\n",
    "gamma = 0.95\n",
    "epsilon_max= 1\n",
    "epsilon_rate = 0.9995\n",
    "epsilon_min = 0.1\n",
    "batch_size = 32\n",
    "memory_replay_size = 100000\n",
    "# self.AGENT_HISTORY_LENGTH = 4\n",
    "target_update_length = 200\n",
    "alpha = 0.00025\n",
    "#   self.GRADIENT_MOMENTUM = 0.95\n",
    "#  self.SQUARED_GRADIENT_MOMENTUM = 0.95\n",
    "# self.MIN_SQUARED_GRADIENT = 0.01\n",
    "replay_start_size = 9000\n",
    "memory = deque(maxlen = 10000)      # ***********************          save and load self.MEMORY       *****************************************\n",
    "#self.MODEL = self.CNN_initialize()\n",
    "#self.TARGET_MODEL = self.CNN_initialize()\n",
    "steps = 0\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,3)\n",
    "        self.conv2 = nn.Conv2d(10,20,3)\n",
    "        self.conv3 = nn.Conv2d(20,30,3)\n",
    "        self.fc1 = nn.Linear( 30*5*5 ,400)\n",
    "        self.fc2 = nn.Linear(400,64)\n",
    "        self.fc3 = nn.Linear(64,10)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.max_pool2d(torch.relu(self.conv2(torch.relu(self.conv1(x)))),(2,2))\n",
    "        x = F.max_pool2d(torch.relu(self.conv3(x)),(2,2))\n",
    "        x = x.view(1,self.num_of_features(x))\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def train(self,X, Y, epochs , batch_size , learning_rate ):\n",
    "        optimizer = optim.SGD(self.parameters(), lr = learning_rate)\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        accuracy = 0.0\n",
    "        for epoch in range(1,epochs+1,1):\n",
    "            if epoch>1:\n",
    "                print('--------------->>>>>>   Epoch {} with accuracy {}'.format(epoch, loss))\n",
    "            permutation = torch.randperm(X.shape[1])\n",
    "            for i in range(0, X.shape[1] - batch_size, batch_size):\n",
    "                optimizer.zero_grad()\n",
    "                indices = permutation[i:i+batch_size]\n",
    "                batchx, batchy = X[indices], Y[indices]\n",
    "                outputs = self.forward(torch.from_numpy(batchx).view(batch_size,1,28,28).float())\n",
    "                loss = criterion(outputs, torch.from_numpy(batchy).view(batch_size,10).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return\n",
    "    \n",
    "    def evaluat(self, X):\n",
    "        #self.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(X.shape[0]):\n",
    "                output = net.forward(torch.from_numpy(X[i]).view(1,1,28,28).float())\n",
    "                plt.subplot(1+X.shape[0]//3,3,i+1)\n",
    "                plt.imshow(np.reshape(X[i],(28,28)))\n",
    "                plt.title('GIVEN : {}'.format(output))\n",
    "        return\n",
    "            \n",
    "    \n",
    "    def num_of_features(self,x):\n",
    "        features = x.size()[1:]\n",
    "        num = 1\n",
    "        for feature in features:\n",
    "            num *= feature\n",
    "        return num\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class game:\n",
    "  def __init__(self,state_size,action_size):\n",
    "    self.state_size=state_size\n",
    "    self.action_size=action_size\n",
    "    self.GAMMA = 0.95\n",
    "    self.EPSILON_MAX = 1\n",
    "    self.EPSILON_RATE = 0.9995\n",
    "    self.EPSILON_MIN = 0.1\n",
    "    self.MINIBATCH_SIZE = 32\n",
    "    self.MEMORY_REPLAY_SIZE = 100000\n",
    "    self.AGENT_HISTORY_LENGTH = 4\n",
    "    self.TARGET_UPDATE_LENGTH = 200\n",
    "    self.ALPHA = 0.00025\n",
    "    self.GRADIENT_MOMENTUM = 0.95\n",
    "    self.SQUARED_GRADIENT_MOMENTUM = 0.95\n",
    "    self.MIN_SQUARED_GRADIENT = 0.01\n",
    "    self.REPLAY_START_SIZE = 9000\n",
    "    self.MEMORY = deque(maxlen = 10000)      # ***********************          save and load self.MEMORY       *****************************************\n",
    "    self.MODEL = self.CNN_initialize()\n",
    "    self.TARGET_MODEL = self.CNN_initialize()\n",
    "    self.STEPS = 0\n",
    "    #Incomplete\n",
    "  \n",
    "  \n",
    "  def target_update(self):\n",
    "    self.TARGET_MODEL.set_weights(self.MODEL.get_weights())\n",
    "  \n",
    "\n",
    "  def CNN_initialize(self):\n",
    "    model = keras.models.Sequential()\n",
    "    # model.add(keras.layers.Conv2D(32,(8,8), strides = (4,4), input_shape = (167,81,1),padding = 'valid'))\n",
    "    # model.add(keras.layers.Activation('relu'))\n",
    "    # model.add(keras.layers.Conv2D(64,(4,4),strides = (2,2), padding = 'valid'))\n",
    "    # model.add(keras.layers.Activation('relu'))\n",
    "    # model.add(keras.layers.Conv2D(64,(3,3),strides = (1,1), padding = 'valid'))\n",
    "    # model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(512,activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(200,activation='relu'))\n",
    "    model.add(keras.layers.Dense(2,kernel_initializer=keras.initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None),activation='linear'))\n",
    "    model.compile(loss = 'mean_squared_error',optimizer= keras.optimizers.Adam(0.0001), metrics=[\"accuracy\"])\n",
    "    return model\n",
    "    # MODEL HERE\n",
    "\n",
    "\n",
    "  def preprocess(self,arr):  \n",
    "    out_arr = arr[0]\n",
    "    out_arr = out_arr[30:197,:]\n",
    "    out_arr = np.delete(out_arr, 2*np.arange(79)+1, axis = 1)\n",
    "    out_arr = out_arr/np.max(out_arr)\n",
    "    out_arr = np.reshape(out_arr, (1,167,81,1))\n",
    "    return out_arr\n",
    "\n",
    "  def preprocess_out(self,arr):  \n",
    "    out_arr = arr[1]\n",
    "    out_arr = out_arr[30:197,:]\n",
    "    out_arr = np.delete(out_arr, 2*np.arange(79)+1, axis = 1)\n",
    "    out_arr = out_arr/np.max(out_arr)\n",
    "    out_arr = np.reshape(out_arr, (1,167,81,1))\n",
    "    return out_arr\n",
    "  \n",
    "  def act(self,state,epsilon):\n",
    "    #if np.random.rand() <= epsilon:\n",
    "     # return np.random.choice(self.action_size)\n",
    "    act_values=self.MODEL.predict(state)\n",
    "    return np.argmax(act_values[0])\n",
    "  \n",
    "  def save(self):\n",
    "    self.MODEL.save_weights('CARTPOLE_MODEL_WEIGHTS_2.h5')                 # ******************  SPECIFY PATH  *********************************\n",
    "    self.TARGET_MODEL.save_weights('CARTPOLE_MODEL_WEIGHTS_2.h5')\n",
    "    print('Model Saved')\n",
    "  \n",
    "  def load(self):\n",
    "    self.MODEL.set_weights('CARTPOLE_MODEL_WEIGHTS.h5')       # ********************** SPECIFY PATH ****************************\n",
    "    self.target_update()\n",
    "    print('Target Loaded')\n",
    "       # UPDATE    CSV   self.Memory\n",
    "  \n",
    "\n",
    "  def remember(self,array):\n",
    "    self.MEMORY.append(array)\n",
    "    #print(len(self.MEMORY))\n",
    "    self.STEPS += 1\n",
    "    if self.STEPS % 2000 == 0:\n",
    "      #pickle.dump(self.MEMORY, file_pi)\n",
    "      self.target_update()\n",
    "      #self.save()\n",
    "      print(str(self.STEPS)+ ' steps completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "agent = game(state_size,action_size)\n",
    "agent.target_update()\n",
    "print('Training Started')\n",
    "agent.load()\n",
    "epsilon = agent.EPSILON_MAX\n",
    "for N in range(20000):\n",
    "  env.reset()\n",
    "  print('Episode Started')\n",
    "  present_img = deque([],maxlen = 2)\n",
    "  tot_reward = 0\n",
    "  y = np.array([0,0])\n",
    "  tot_reward = 0\n",
    "  present_img.append(env.reset())\n",
    "  T =0\n",
    "  done = False\n",
    "  while done == False:\n",
    "    T += 1\n",
    "    #if T%100==0:\n",
    "      #print(str(T)+' TIME STEPS DONE')\n",
    "      #print(tot_reward)\n",
    "      #print(len(agent.MEMORY))\n",
    "      # *******************************COMPUTE Q OUTPUT ******************************\n",
    "    done = False                                                                             #next_state,reward,done,info\n",
    "    train_img = present_img[0]\n",
    "    Action = agent.act(train_img,epsilon)\n",
    "\n",
    "    \n",
    "\n",
    "    out = env.step(Action)\n",
    "    env.render()\n",
    "    #sleep(0.005)\n",
    "    tot_reward += out[1]\n",
    "    done = out[2]\n",
    "    present_img.append(out[0])\n",
    "\n",
    "    next_img = present_img[1] #***************************************\n",
    "    agent.remember((train_img,out[1],Action, next_img,done))\n",
    "\n",
    "      \n",
    "\n",
    "    if len(agent.MEMORY) > agent.REPLAY_START_SIZE:\n",
    "      #print('Updating Model')\n",
    "      epsilon = max(epsilon,agent.EPSILON_MIN)\n",
    "      epsilon = epsilon * agent.EPSILON_RATE\n",
    "      indices = np.random.choice(np.arange(0,len(agent.MEMORY)-1,1),32)\n",
    "      batch = [agent.MEMORY[i] for i in indices]\n",
    "      for img_input,Reward,action,target_input,over in batch:\n",
    "        y = agent.MODEL.predict(img_input)\n",
    "        if over:\n",
    "          y[0][action] = Reward - np.abs(img_input[2])/50\n",
    "        else:\n",
    "          y[0][action] = Reward - np.abs(img_input[2])/50 + agent.GAMMA * np.amax(agent.TARGET_MODEL.predict(target_input)[0])\n",
    "        agent.MODEL.fit(img_input,y,epochs = 1, verbose = 0)  \n",
    "\n",
    "\n",
    "    if done:\n",
    "      print(\"Episode {}/{} finished after {} timesteps epsilon:{} total reward:{} total steps:{}\".format(N,20000,T+1,epsilon,tot_reward,agent.STEPS))\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
